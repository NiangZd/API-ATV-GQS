{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiangZd/API-ATV-GQS/blob/main/Pipeline_de_Classifica%C3%A7%C3%A3o_MNIST_(dividido_em_c%C3%A9lulas).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pipeline de Classificação MNIST (Dividido em Células)\n",
        "# **Etapas:**\n",
        "# * a) Avaliação com `cross_val_predict` (em um subset rápido)\n",
        "# * b) Ranqueamento por Acurácia CV (Top 3)\n",
        "# * c) Avaliação em um conjunto de teste inicial (treinado no subset rápido)\n",
        "# * d) Ranqueamento por estabilidade (Diferença CV-Teste) (Top 3)\n",
        "# * e) `RandomizedSearchCV` nos Top 3 de estabilidade (usando subset rápido)\n",
        "# * f) Avaliação dos modelos otimizados em um NOVO conjunto de teste (treinado no set completo)\n",
        "# * g) Exportação do melhor modelo final com `joblib`.\n",
        "\n",
        "# ## Célula 1: Importações\n",
        "# Importa todas as bibliotecas necessárias.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import warnings\n",
        "import time\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import cross_val_predict, train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "PbmAfJon3UTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 2: Configuração Inicial\n",
        "# Define as constantes globais, SEEDs e configurações do pipeline.\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Constantes de configuração\n",
        "SEED = 42\n",
        "N_ITER_RANDOM = 10  # N de combinações para o RandomizedSearch\n",
        "N_FOLDS_CV = 3      # N de folds para a validação cruzada\n",
        "FAST_SUBSET_SIZE = 10000 # Tamanho do subset para rodar rápido\n",
        "MODEL_FILENAME = 'best_mnist_model.joblib'\n",
        "\n",
        "np.random.seed(SEED)\n",
        "print(f\"Iniciando pipeline de classificação MNIST...\")\n",
        "print(f\"Configurações: SEED={SEED}, N_ITER_RANDOM={N_ITER_RANDOM}, N_FOLDS_CV={N_FOLDS_CV}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58vmtDFE4bAA",
        "outputId": "27f0bf56-315d-4ecd-8f29-6f5341e2fda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando pipeline de classificação MNIST...\n",
            "Configurações: SEED=42, N_ITER_RANDOM=10, N_FOLDS_CV=3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 3: Carga e Pré-processamento dos Dados\n",
        "# Carrega o dataset MNIST e aplica o `StandardScaler`.\n",
        "\n",
        "print(\"Carregando dataset MNIST (pode levar um momento)...\")\n",
        "# Carrega 70.000 imagens (28x28 = 784 features)\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype(np.uint8)\n",
        "\n",
        "print(\"Pré-processando os dados...\")\n",
        "# Normalização (StandardScaler)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Dados carregados e normalizados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_xN56vD4pDq",
        "outputId": "c63eb29a-3b74-4893-db49-a758f75a20cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando dataset MNIST (pode levar um momento)...\n",
            "Pré-processando os dados...\n",
            "Dados carregados e normalizados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 4: Estratégia de Divisão (Splitting) Robusta\n",
        "# Divide os dados em múltiplos conjuntos\n",
        "\n",
        "print(\"Dividindo os dados...\")\n",
        "\n",
        "# Split A: Separa o conjunto de \"Teste Final\" (10k).\n",
        "X_train_val, X_test_final, y_train_val, y_test_final = train_test_split(\n",
        "    X_scaled, y, test_size=10000, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "# X_train_val: 60k amostras\n",
        "# X_test_final: 10k amostras\n",
        "\n",
        "# Split B: Separa o \"Teste Inicial\" (10k) do conjunto de treino/validação.\n",
        "X_train_full, X_test_initial, y_train_full, y_test_initial = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=10000, random_state=SEED, stratify=y_train_val\n",
        ")\n",
        "\n",
        "# X_train_full: 50k amostras\n",
        "# X_test_initial: 10k amostras\n",
        "\n",
        "# Split C: Cria o \"Subset Rápido\" (10k).\n",
        "# Usamos 'train_size' para pegar uma fração de X_train_full\n",
        "_, X_train_fast, _, y_train_fast = train_test_split(\n",
        "    X_train_full, y_train_full, train_size=FAST_SUBSET_SIZE, random_state=SEED, stratify=y_train_full\n",
        ")\n",
        "# X_train_fast: 10k amostras (usado para CV rápido e RandomSearch)\n",
        "\n",
        "print(f\"Divisão de dados concluída:\")\n",
        "print(f\" - Subset de Treino/CV Rápido (a,c,e): {X_train_fast.shape[0]} amostras\")\n",
        "print(f\" - Teste Inicial (c):                 {X_test_initial.shape[0]} amostras\")\n",
        "print(f\" - Treino Completo (f):               {X_train_val.shape[0]} amostras\")\n",
        "print(f\" - Teste Final (f):                   {X_test_final.shape[0]} amostras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCSkbI1j4tCO",
        "outputId": "0e0121c7-b798-4415-a2fa-6cb02fb7015a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dividindo os dados...\n",
            "Divisão de dados concluída:\n",
            " - Subset de Treino/CV Rápido (a,c,e): 40000 amostras\n",
            " - Teste Inicial (c):                 10000 amostras\n",
            " - Treino Completo (f):               60000 amostras\n",
            " - Teste Final (f):                   10000 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 5: Definição dos Modelos Base\n",
        "# Cria o dicionário `models` com os 7 classificadores usando seus hiperparâmetros default.\n",
        "\n",
        "models = {\n",
        "    \"NaiveBayes\": GaussianNB(),\n",
        "    \"MLP\": MLPClassifier(random_state=SEED, max_iter=300),\n",
        "    \"KNN\": KNeighborsClassifier(n_jobs=-1),\n",
        "    \"Regressão Logística\": LogisticRegression(random_state=SEED, max_iter=200, n_jobs=-1),\n",
        "    \"SGD\": SGDClassifier(random_state=SEED, max_iter=200, n_jobs=-1),\n",
        "    \"XGBoost\": XGBClassifier(random_state=SEED, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1),\n",
        "    \"Árvore de Decisão\": DecisionTreeClassifier(random_state=SEED)\n",
        "}\n",
        "print(f\"{len(models)} modelos base definidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6EWTB1d4zTm",
        "outputId": "66d34ee3-d139-4921-e235-dfe9f5cb7e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 modelos base definidos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 6: Definição das Distribuições de Hiperparâmetros\n",
        "# Cria o dicionário `param_distributions` para a busca aleatória\n",
        "\n",
        "param_distributions = {\n",
        "    \"NaiveBayes\": {\n",
        "        'var_smoothing': uniform(1e-10, 1e-8)\n",
        "    },\n",
        "    \"MLP\": {\n",
        "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "        'activation': ['relu', 'tanh'],\n",
        "        'alpha': uniform(1e-5, 1e-3),\n",
        "        'learning_rate_init': uniform(0.001, 0.01)\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        'n_neighbors': randint(3, 9),\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'p': [1, 2]\n",
        "    },\n",
        "    \"Regressão Logística\": {\n",
        "        'C': uniform(0.1, 10),\n",
        "        'solver': ['saga'],\n",
        "        'penalty': ['l1', 'l2']\n",
        "    },\n",
        "    \"SGD\": {\n",
        "        'loss': ['hinge', 'log_loss'],\n",
        "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "        'alpha': uniform(1e-5, 1e-3)\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        'n_estimators': randint(50, 200),\n",
        "        'learning_rate': uniform(0.01, 0.2),\n",
        "        'max_depth': randint(3, 7)\n",
        "    },\n",
        "    \"Árvore de Decisão\": {\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_depth': randint(5, 20),\n",
        "        'min_samples_split': randint(2, 20)\n",
        "    }\n",
        "}\n",
        "print(\"Distribuições de hiperparâmetros definidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8U0_Of44_C",
        "outputId": "bbab13ad-7cd8-456b-ac4b-c7d22cb640fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuições de hiperparâmetros definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 7: Inicialização de Variáveis\n",
        "# Prepara os dicionários para armazenar resultados e marca o tempo de início.\n",
        "\n",
        "# Dicionários para guardar resultados\n",
        "cv_results = {}\n",
        "test_results = {}\n",
        "final_results = {}\n",
        "best_tuned_models = {}\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"Variáveis de resultado inicializadas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWsMfzCb5CZc",
        "outputId": "12e510b7-7896-4471-ff0e-ca5a47ecdd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variáveis de resultado inicializadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 8: Etapa (a) - Validação Cruzada (CV)\n",
        "# Avalia os 7 modelos default usando `cross_val_predict` no *subset rápido* (10k amostras).\n",
        "\n",
        "print(\"\\n--- Etapa (a): Iniciando Validação Cruzada (CV) ---\")\n",
        "print(f\"(Usando {X_train_fast.shape[0]} amostras e {N_FOLDS_CV} folds)\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    t0 = time.time()\n",
        "    print(f\"Avaliando {name}...\")\n",
        "    y_pred_cv = cross_val_predict(model, X_train_fast, y_train_fast, cv=N_FOLDS_CV, n_jobs=-1)\n",
        "    acc_cv = accuracy_score(y_train_fast, y_pred_cv)\n",
        "    cv_results[name] = acc_cv\n",
        "    print(f\"  -> {name} | Acurácia CV: {acc_cv:.4f} (levou {time.time()-t0:.2f}s)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrUPzkbN5GJQ",
        "outputId": "a3befd52-076e-400d-c730-b1e70aa8ceca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Etapa (a): Iniciando Validação Cruzada (CV) ---\n",
            "(Usando 40000 amostras e 3 folds)\n",
            "Avaliando NaiveBayes...\n",
            "  -> NaiveBayes | Acurácia CV: 0.5424 (levou 6.43s)\n",
            "Avaliando MLP...\n",
            "  -> MLP | Acurácia CV: 0.9646 (levou 59.63s)\n",
            "Avaliando KNN...\n",
            "  -> KNN | Acurácia CV: 0.9324 (levou 70.59s)\n",
            "Avaliando Regressão Logística...\n",
            "  -> Regressão Logística | Acurácia CV: 0.8978 (levou 71.31s)\n",
            "Avaliando SGD...\n",
            "  -> SGD | Acurácia CV: 0.9098 (levou 133.29s)\n",
            "Avaliando XGBoost...\n",
            "  -> XGBoost | Acurácia CV: 0.9686 (levou 799.42s)\n",
            "Avaliando Árvore de Decisão...\n",
            "  -> Árvore de Decisão | Acurácia CV: 0.8489 (levou 29.57s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 9: Etapa (c) - Avaliação no Teste Inicial\n",
        "# Treina os modelos default no *subset rápido* (10k) e avalia no *teste inicial* (10k).\n",
        "\n",
        "print(\"\\n--- Etapa (c): Avaliando no Teste Inicial ---\")\n",
        "print(f\"(Treinando em {X_train_fast.shape[0]}, testando em {X_test_initial.shape[0]})\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    t0 = time.time()\n",
        "    print(f\"Treinando e testando {name}...\")\n",
        "    model.fit(X_train_fast, y_train_fast) # Treina no subset rápido\n",
        "    y_pred_test = model.predict(X_test_initial) # Testa no teste inicial\n",
        "    acc_test = accuracy_score(y_test_initial, y_pred_test)\n",
        "    test_results[name] = acc_test\n",
        "    print(f\"  -> {name} | Acurácia Teste Inicial: {acc_test:.4f} (levou {time.time()-t0:.2f}s)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1ExJN4C5J48",
        "outputId": "b71a0855-cb3d-4985-9a25-7cf4b76c6b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Etapa (c): Avaliando no Teste Inicial ---\n",
            "(Treinando em 40000, testando em 10000)\n",
            "Treinando e testando NaiveBayes...\n",
            "  -> NaiveBayes | Acurácia Teste Inicial: 0.5476 (levou 0.94s)\n",
            "Treinando e testando MLP...\n",
            "  -> MLP | Acurácia Teste Inicial: 0.9706 (levou 40.61s)\n",
            "Treinando e testando KNN...\n",
            "  -> KNN | Acurácia Teste Inicial: 0.9452 (levou 27.32s)\n",
            "Treinando e testando Regressão Logística...\n",
            "  -> Regressão Logística | Acurácia Teste Inicial: 0.9087 (levou 40.72s)\n",
            "Treinando e testando SGD...\n",
            "  -> SGD | Acurácia Teste Inicial: 0.9164 (levou 63.25s)\n",
            "Treinando e testando XGBoost...\n",
            "  -> XGBoost | Acurácia Teste Inicial: 0.9769 (levou 390.39s)\n",
            "Treinando e testando Árvore de Decisão...\n",
            "  -> Árvore de Decisão | Acurácia Teste Inicial: 0.8667 (levou 16.21s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 10: Etapa (b) - Ranqueamento por Acurácia CV (Top 3)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Acuracia_CV': cv_results,\n",
        "    'Acuracia_Teste': test_results\n",
        "})\n",
        "results_df['Diferenca_Abs'] = abs(results_df['Acuracia_CV'] - results_df['Acuracia_Teste'])\n",
        "\n",
        "print(\"\\nDataFrame de Resultados (CV vs Teste Inicial):\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "print(\"\\n--- Etapa (b): Ranqueamento por Acurácia CV ---\")\n",
        "results_cv_ranked = results_df.sort_values(by='Acuracia_CV', ascending=False)\n",
        "print(results_cv_ranked[['Acuracia_CV']])\n",
        "top_3_cv_names = results_cv_ranked.index[:3].tolist()\n",
        "print(f\"\\nTop 3 (Acurácia CV): {', '.join(top_3_cv_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8ImiO9-5NT0",
        "outputId": "ed4672dd-78bd-4683-9431-27aa8d43c10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame de Resultados (CV vs Teste Inicial):\n",
            "                     Acuracia_CV  Acuracia_Teste  Diferenca_Abs\n",
            "NaiveBayes                0.5424          0.5476         0.0052\n",
            "MLP                       0.9646          0.9706         0.0060\n",
            "KNN                       0.9324          0.9452         0.0128\n",
            "Regressão Logística       0.8978          0.9087         0.0109\n",
            "SGD                       0.9098          0.9164         0.0066\n",
            "XGBoost                   0.9686          0.9769         0.0083\n",
            "Árvore de Decisão         0.8489          0.8667         0.0178\n",
            "\n",
            "--- Etapa (b): Ranqueamento por Acurácia CV ---\n",
            "                     Acuracia_CV\n",
            "XGBoost                 0.968600\n",
            "MLP                     0.964550\n",
            "KNN                     0.932425\n",
            "SGD                     0.909775\n",
            "Regressão Logística     0.897800\n",
            "Árvore de Decisão       0.848875\n",
            "NaiveBayes              0.542375\n",
            "\n",
            "Top 3 (Acurácia CV): XGBoost, MLP, KNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 11: Ranqueamento por Estabilidade e Análise\n",
        "# Classifica os modelos pela menor `Diferenca_Abs` (CV vs Teste) e identifica o Top 3 (modelos mais estáveis),\n",
        "# e analisa a diferença entre os Top 3 de acurácia e estabilidade.\n",
        "\n",
        "print(\"\\n--- Etapa (d): Ranqueamento por Estabilidade (Menor Diferença CV-Teste) ---\")\n",
        "results_diff_ranked = results_df.sort_values(by='Diferenca_Abs', ascending=True)\n",
        "print(results_diff_ranked[['Acuracia_CV', 'Acuracia_Teste', 'Diferenca_Abs']].round(4))\n",
        "top_3_stability_names = results_diff_ranked.index[:3].tolist()\n",
        "print(f\"\\nTop 3 (Estabilidade): {', '.join(top_3_stability_names)}\")\n",
        "\n",
        "# Análise (d)\n",
        "print(\"\\n--- Análise (d): Melhores CV vs. Mais Estáveis ---\")\n",
        "coincidem = set(top_3_cv_names) == set(top_3_stability_names)\n",
        "print(f\"Top 3 Acurácia:   {top_3_cv_names}\")\n",
        "print(f\"Top 3 Estabilidade: {top_3_stability_names}\")\n",
        "print(f\"Os conjuntos {'COINCIDEM' if coincidem else 'NÃO COINCIDEM'}.\")\n",
        "print(\"Frequentemente, os modelos mais precisos (ex: XGB, MLP) podem ter mais overfitting\")\n",
        "print(\"com parâmetros default, mostrando uma diferença maior, enquanto modelos mais simples\")\n",
        "print(\"(ex: Regressão Logística, NaiveBayes) são mais estáveis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxxDMLYI5SP4",
        "outputId": "6b98abd7-3593-432a-d57a-cb04afe4ac3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Etapa (d): Ranqueamento por Estabilidade (Menor Diferença CV-Teste) ---\n",
            "                     Acuracia_CV  Acuracia_Teste  Diferenca_Abs\n",
            "NaiveBayes                0.5424          0.5476         0.0052\n",
            "MLP                       0.9646          0.9706         0.0060\n",
            "SGD                       0.9098          0.9164         0.0066\n",
            "XGBoost                   0.9686          0.9769         0.0083\n",
            "Regressão Logística       0.8978          0.9087         0.0109\n",
            "KNN                       0.9324          0.9452         0.0128\n",
            "Árvore de Decisão         0.8489          0.8667         0.0178\n",
            "\n",
            "Top 3 (Estabilidade): NaiveBayes, MLP, SGD\n",
            "\n",
            "--- Análise (d): Melhores CV vs. Mais Estáveis ---\n",
            "Top 3 Acurácia:   ['XGBoost', 'MLP', 'KNN']\n",
            "Top 3 Estabilidade: ['NaiveBayes', 'MLP', 'SGD']\n",
            "Os conjuntos NÃO COINCIDEM.\n",
            "Frequentemente, os modelos mais precisos (ex: XGB, MLP) podem ter mais overfitting\n",
            "com parâmetros default, mostrando uma diferença maior, enquanto modelos mais simples\n",
            "(ex: Regressão Logística, NaiveBayes) são mais estáveis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 12: - Randomized Search (Otimização)\n",
        "# Executa o `RandomizedSearchCV` (com `N_ITER_RANDOM` iterações) nos **Top 3 de estabilidade**,\n",
        "# usando o *subset rápido* (10k) para agilidade.\n",
        "\n",
        "print(f\"\\n--- Etapa (e): Randomized Search (N={N_ITER_RANDOM}) nos Top 3 de Estabilidade ---\")\n",
        "print(f\"(Usando {X_train_fast.shape[0]} amostras para a busca)\")\n",
        "\n",
        "models_to_tune = {name: models[name] for name in top_3_stability_names}\n",
        "\n",
        "for name, model in models_to_tune.items():\n",
        "    t0 = time.time()\n",
        "    print(f\"\\nOtimizando {name}...\")\n",
        "\n",
        "    if name not in param_distributions:\n",
        "        print(f\"  -> Sem distribuição de parâmetros definida para {name}. Pulando.\")\n",
        "        best_tuned_models[name] = model\n",
        "        continue\n",
        "\n",
        "    rand_search = RandomizedSearchCV(\n",
        "        model,\n",
        "        param_distributions[name],\n",
        "        n_iter=N_ITER_RANDOM,\n",
        "        cv=N_FOLDS_CV,\n",
        "        scoring='accuracy',\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Ajusta a busca no subset rápido\n",
        "    rand_search.fit(X_train_fast, y_train_fast)\n",
        "\n",
        "    best_tuned_models[name] = rand_search.best_estimator_ # Guarda o melhor modelo\n",
        "\n",
        "    print(f\"  -> {name} Concluído (levou {time.time()-t0:.2f}s)\")\n",
        "    print(f\"  -> Melhor Acurácia CV (na busca): {rand_search.best_score_:.4f}\")\n",
        "    print(f\"  -> Melhores Parâmetros: {rand_search.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFcshX8k5VQo",
        "outputId": "3d22f447-8593-4ee0-fdc1-e497b55e2f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Etapa (e): Randomized Search (N=10) nos Top 3 de Estabilidade ---\n",
            "(Usando 40000 amostras para a busca)\n",
            "\n",
            "Otimizando NaiveBayes...\n",
            "  -> NaiveBayes Concluído (levou 32.16s)\n",
            "  -> Melhor Acurácia CV (na busca): 0.5516\n",
            "  -> Melhores Parâmetros: {'var_smoothing': np.float64(9.607143064099161e-09)}\n",
            "\n",
            "Otimizando MLP...\n",
            "  -> MLP Concluído (levou 506.85s)\n",
            "  -> Melhor Acurácia CV (na busca): 0.9671\n",
            "  -> Melhores Parâmetros: {'activation': 'relu', 'alpha': np.float64(0.000606850157946487), 'hidden_layer_sizes': (100,), 'learning_rate_init': np.float64(0.0025599452033620265)}\n",
            "\n",
            "Otimizando SGD...\n",
            "  -> SGD Concluído (levou 5569.68s)\n",
            "  -> Melhor Acurácia CV (na busca): 0.9088\n",
            "  -> Melhores Parâmetros: {'alpha': np.float64(0.00016601864044243653), 'loss': 'hinge', 'penalty': 'elasticnet'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 13:- Avaliação Final (no Teste Final)\n",
        "# Re-treina os 3 modelos otimizados no *conjunto de treino completo* (60k)\n",
        "# e avalia no *conjunto de teste final* (10k).\n",
        "\n",
        "print(\"\\n--- Etapa (f): Avaliação Final no Conjunto de Teste Final (10k) ---\")\n",
        "print(f\"(Re-treinando os 3 melhores modelos em {X_train_val.shape[0]} amostras)\")\n",
        "\n",
        "for name, model in best_tuned_models.items():\n",
        "    t0 = time.time()\n",
        "    print(f\"Re-treinando e avaliando {name} otimizado...\")\n",
        "\n",
        "    # Re-treina o modelo (com os melhores params) no conjunto de treino COMPLETO (60k)\n",
        "    model.fit(X_train_val, y_train_val)\n",
        "\n",
        "    # Avalia no conjunto de teste FINAL (10k)\n",
        "    y_pred_final = model.predict(X_test_final)\n",
        "    acc_final = accuracy_score(y_test_final, y_pred_final)\n",
        "    final_results[name] = acc_final\n",
        "\n",
        "    print(f\"  -> {name} | Acurácia FINAL: {acc_final:.4f} (levou {time.time()-t0:.2f}s)\")\n",
        "\n",
        "    # Guarda o modelo treinado nos 60k\n",
        "    best_tuned_models[name] = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEklgTln5Yuk",
        "outputId": "327b1277-f8d9-4e21-b94f-fc6c73b8ceef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Etapa (f): Avaliação Final no Conjunto de Teste Final (10k) ---\n",
            "(Re-treinando os 3 melhores modelos em 60000 amostras)\n",
            "Re-treinando e avaliando NaiveBayes otimizado...\n",
            "  -> NaiveBayes | Acurácia FINAL: 0.5377 (levou 1.48s)\n",
            "Re-treinando e avaliando MLP otimizado...\n",
            "  -> MLP | Acurácia FINAL: 0.9703 (levou 51.49s)\n",
            "Re-treinando e avaliando SGD otimizado...\n",
            "  -> SGD | Acurácia FINAL: 0.9140 (levou 445.13s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Célula 14: - Seleção e Exportação do Melhor Modelo\n",
        "# Seleciona o melhor modelo com base na acurácia final e salva o modelo\n",
        "\n",
        "print(\"\\n--- Etapa (g): Seleção e Exportação do Melhor Modelo ---\")\n",
        "\n",
        "if not final_results:\n",
        "    print(\"ERRO: Nenhum resultado final foi gerado. Não é possível exportar.\")\n",
        "else:\n",
        "    # Cria uma Series para facilitar a ordenação\n",
        "    final_results_series = pd.Series(final_results).sort_values(ascending=False)\n",
        "\n",
        "    print(\"Ranking Final (Pós-Otimização, Teste Final):\")\n",
        "    print(final_results_series)\n",
        "\n",
        "    # Pega o nome e a acurácia do melhor\n",
        "    best_overall_name = final_results_series.idxmax()\n",
        "    best_overall_accuracy = final_results_series.max()\n",
        "\n",
        "    # Pega o objeto do modelo (já treinado nos 60k)\n",
        "    model_to_export = best_tuned_models[best_overall_name]\n",
        "\n",
        "    print(f\"\\nMelhor modelo geral: {best_overall_name} (Acurácia: {best_overall_accuracy:.4f})\")\n",
        "\n",
        "    scaler_filename = 'mnist_scaler.joblib'\n",
        "    joblib.dump(scaler, scaler_filename)\n",
        "    joblib.dump(model_to_export, MODEL_FILENAME)\n",
        "\n",
        "    print(f\"\\nModelo salvo com sucesso em: {MODEL_FILENAME}\")\n",
        "    print(f\"Scaler salvo com sucesso em: {scaler_filename}\")\n",
        "\n",
        "print(f\"\\n--- Pipeline Concluído ---\")\n",
        "print(f\"Tempo total de execução: {(time.time() - start_time) / 60:.2f} minutos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX8LSgPa5bhI",
        "outputId": "ee628501-e9a3-4653-cbde-de43c51bbd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Etapa (g): Seleção e Exportação do Melhor Modelo ---\n",
            "Ranking Final (Pós-Otimização, Teste Final):\n",
            "MLP           0.9703\n",
            "SGD           0.9140\n",
            "NaiveBayes    0.5377\n",
            "dtype: float64\n",
            "\n",
            "Melhor modelo geral: MLP (Acurácia: 0.9703)\n",
            "\n",
            "Modelo salvo com sucesso em: best_mnist_model.joblib\n",
            "Scaler salvo com sucesso em: mnist_scaler.joblib\n",
            "\n",
            "--- Pipeline Concluído ---\n",
            "Tempo total de execução: 145.17 minutos\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}